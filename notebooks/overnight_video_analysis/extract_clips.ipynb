{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process videos for inference and training\n",
    "\n",
    "Takes a folder with a set of recording in it and crops them and saves them organize by camera used. If desired will create a 'training' dataset also, which is a random sample of shorter clips extracted from the whole dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters here. Need to specify path to a file, `crops.csv`, that contains crop information for each recording. As an example, this file has the format:\n",
    "\n",
    "```\n",
    ",source_video_name,top,left,right,bottom,camera,experiment,animal\n",
    "0,e3v813a-20220131T174814-181650,200,0,460,0,e3v813a,Overnight Videos,Animal 1\n",
    "1,e3v813a-20220201T195224-202053,200,0,460,0,e3v813a,Overnight Videos,Animal 2\n",
    "2,e3v813a-20220202T210531-213427,200,0,460,0,e3v813a,Overnight Videos,Animal 3\n",
    "```\n",
    "where `top, left, right, bottom` indicate the number of pixels to remove from that respective side. When applying the crop, videos are matched according to the `animal`, `camera` and `experiment` in this table to determine what crop to apply. If data is missing from this table, no crop is applied.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameteres for training data\n",
    "sample_dur = 300 # amount to extract, in seconds\n",
    "n_samples = 10   # number of videos per camera to extract\n",
    "\n",
    "\n",
    "#Overnight videos\n",
    "# create_training_data = True\n",
    "# raw_video_path = '/home/blansdel/ImageAnalysisScratch/Zakharenko/Brett videos/Overnight Videos/'\n",
    "# inference_video_path = '/home/blansdel/ImageAnalysisScratch/Zakharenko/animal-behavior-ml/inference'\n",
    "# train_video_path = '/home/blansdel/ImageAnalysisScratch/Zakharenko/animal-behavior-ml/training/'\n",
    "# crops_path = '/home/blansdel/projects/dlc_training/behavior-ml-analysis/scripts/crops.csv'\n",
    "# ext = 'avi'\n",
    "\n",
    "#Overnight videos LSD\n",
    "\n",
    "#Input video path\n",
    "raw_video_path = '/home/blansdel/ImageAnalysisScratch/Zakharenko/Brett videos/Overnight Videos LSD/'\n",
    "\n",
    "#Output path for inference videos\n",
    "inference_video_path = '/home/blansdel/ImageAnalysisScratch/AnimalBehaviorCore/Zakharenko/animal-behavior-ml/inference'\n",
    "\n",
    "#Output path for training videos\n",
    "train_video_path = '/home/blansdel/ImageAnalysisScratch/AnimalBehaviorCore/Zakharenko/animal-behavior-ml/training/'\n",
    "\n",
    "create_training_data = False #Whether to save data to train_video_path\n",
    "crops_path = '/mnt/storage2/blansdel/projects/dlc_training/behavior-ml-analysis/scripts/crops.csv'\n",
    "ext = 'avi' #Input file extension \n",
    "\n",
    "trial_run = False #If true: don't actually run commands, just print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def crop_videos(videos, out_base_dir, crops, trial_run = False):\n",
    "\n",
    "    for vid in videos:\n",
    "        #Get data about video \n",
    "        an = vid.split('/')[-2]\n",
    "        camera = vid.split('/')[-1].split('.')[0].split('-')[0]\n",
    "        expt = vid.split('/')[-3]\n",
    "        out_dir = os.path.join(out_base_dir, expt, an, camera)\n",
    "\n",
    "        vid_ = vid.replace(' ', '\\ ')\n",
    "        out_dir = out_dir.replace(' ', '\\ ')\n",
    "        os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "        crop_ps = crops.loc[(crops.camera == camera) & (crops.experiment == expt) & (crops.animal == an),\n",
    "                            ['top', 'left', 'right', 'bottom']].to_numpy().squeeze()\n",
    "\n",
    "        if len(crop_ps) == 0:\n",
    "            print('No crop data found for {}, just copying as is instead.'.format(vid))\n",
    "            cmd = 'cp {} {}'.format(vid_, out_dir)\n",
    "            if trial_run:\n",
    "                print(cmd)\n",
    "            else:\n",
    "                os.system(cmd)\n",
    "            continue\n",
    "\n",
    "        width = crop_ps[2] + crop_ps[1]\n",
    "        height = crop_ps[0] + crop_ps[3]\n",
    "        left = crop_ps[1]\n",
    "        top = crop_ps[0]\n",
    "        cmd = 'ffmpeg -i ' + vid_ + ' -c:v libx264 -crf 10 -filter:v \"crop=in_w-' + str(width) + ':in_h-' \\\n",
    "            + str(height) + ':' + str(left) + ':' + \\\n",
    "            str(top) + '\" -y \"' + os.path.join(out_dir, os.path.basename(vid_.replace(f'.{ext}', '_cropped.mp4'))) + '\"'\n",
    "        if trial_run:\n",
    "            print(cmd)\n",
    "        else:\n",
    "            os.system(cmd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = glob(os.path.join(raw_video_path, '*'))\n",
    "crops = pd.read_csv(crops_path, index_col = 0)\n",
    "\n",
    "video_files = []\n",
    "for dr in animals:\n",
    "    video_files += glob(os.path.join(dr, f'*.{ext}'))\n",
    "\n",
    "crop_videos(video_files, inference_video_path, crops, trial_run = trial_run)\n",
    "\n",
    "cameras = crops['camera'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if create_training_data:\n",
    "    inference_vids = glob(inference_video_path + '/*/*/*/*_cropped.mp4')\n",
    "    camera_inference_videos = [v.split('/')[-2] for v in inference_vids]\n",
    "    animal_inference_videos = [v.split('/')[-3] for v in inference_vids]\n",
    "\n",
    "    inferences = pd.DataFrame({'video': inference_vids, 'camera': camera_inference_videos, 'animal': animal_inference_videos})\n",
    "    animals = inferences['animal'].unique()\n",
    "\n",
    "    for cam in cameras:\n",
    "        cam_inferences = inferences.loc[inferences.camera == cam]\n",
    "        n_animals_w_this_camera = len(cam_inferences['animal'].unique())\n",
    "        samples_per_animal = n_samples // n_animals_w_this_camera\n",
    "        for an in cam_inferences['animal'].unique():\n",
    "            cam_inferences_ = cam_inferences.loc[cam_inferences.animal == an.replace('//', '/')]\n",
    "            #Randomly select n_samples from each camera\n",
    "            cam_inferences_sample = cam_inferences_.sample(n = samples_per_animal)\n",
    "            #Use ffmpeg to extract sample_dur from each of these videos\n",
    "            for i, vid in cam_inferences_sample.iterrows():\n",
    "                vid_ = vid.video\n",
    "                an = vid_.split('/')[-3]\n",
    "                camera = vid_.split('/')[-1].split('.')[0].split('-')[0]\n",
    "                expt = vid_.split('/')[-4]\n",
    "                out_dir = os.path.join(train_video_path, expt, camera, an)\n",
    "                os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "                cmd = 'ffmpeg -i \"' + vid_ + '\" -c:v copy -t ' + str(sample_dur) + \\\n",
    "                    ' -y \"' + os.path.join(out_dir, os.path.basename(vid.video.replace(f'.{ext}', '_sample.mp4'))) + '\"'\n",
    "                if trial_run:\n",
    "                    print(cmd)\n",
    "                else:\n",
    "                    os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('DEEPLABCUT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c87c97cd47101481760159e33205eeaa3628845dbc4f7c163ec91ff4718b79bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
